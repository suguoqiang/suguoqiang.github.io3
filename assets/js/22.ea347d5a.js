(window.webpackJsonp=window.webpackJsonp||[]).push([[22],{517:function(t,s,a){"use strict";a.r(s);var n=a(6),e=Object(n.a)({},(function(){var t=this,s=t.$createElement,a=t._self._c||s;return a("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[a("h3",{attrs:{id:"基本知识"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#基本知识"}},[t._v("#")]),t._v(" 基本知识")]),t._v(" "),a("h4",{attrs:{id:"简介"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#简介"}},[t._v("#")]),t._v(" 简介")]),t._v(" "),a("p",[t._v("ElasticSearch（简称ES）是一个分布式、Restful的搜索及分析服务器，设计用于分布式计算；能够达到实时搜索，稳定，可靠，快速。和Apache Solr一样，它也是基于Lucence的索引服务器，")]),t._v(" "),a("p",[t._v("而ElasticSearch对比Solr的优点在于：")]),t._v(" "),a("ul",[a("li",[t._v("轻量级：安装启动方便，下载文件之后一条命令就可以启动。")]),t._v(" "),a("li",[t._v("Schema free：可以向服务器提交任意结构的JSON对象，Solr中使用schema.xml指定了索引结构。")]),t._v(" "),a("li",[t._v("多索引文件支持：使用不同的index参数就能创建另一个索引文件，Solr中需要另行配置。")]),t._v(" "),a("li",[t._v("分布式：Solr Cloud的配置比较复杂。")])]),t._v(" "),a("p",[t._v("2013年初，GitHub抛弃了Solr，采取ElasticSearch 来做PB级的搜索。")]),t._v(" "),a("p",[t._v("近年ElasticSearch发展迅猛，已经超越了其最初的纯搜索引擎的角色，现在已经增加了数据聚合分析（aggregation）和可视化的特性，")]),t._v(" "),a("p",[t._v("如果你有数百万的文档需要通过关键词进行定位时，ElasticSearch肯定是最佳选择。当然，如果你的文档是JSON的，你也可以把ElasticSearch当作一种“NoSQL数据库”， 应用ElasticSearch数据聚合分析（aggregation）的特性，针对数据进行多维度的分析。")]),t._v(" "),a("p",[t._v("ElasticSearch一些国内外的优秀案例：")]),t._v(" "),a("p",[t._v("Github：“GitHub使用ElasticSearch搜索20TB的数据，包括13亿文件和1300亿行代码”。")]),t._v(" "),a("p",[t._v("SoundCloud：“SoundCloud使用ElasticSearch为1.8亿用户提供即时而精准的音乐搜索服务”。")]),t._v(" "),a("p",[t._v("百度：百度目前广泛使用ElasticSearch作为文本数据分析，采集百度所有服务器上的各类指标数据及用户自定义数据，通过对各种数据进行多维分析展示，辅助定位分析实例异常或业务层面异常。目前覆盖百度内部20多个业务线（包括casio、云分析、网盟、预测、文库、直达号、钱包、风控等），单集群最大100台机器，200个ES节点，每天导入30TB+数据。")]),t._v(" "),a("h4",{attrs:{id:"概念"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#概念"}},[t._v("#")]),t._v(" 概念")]),t._v(" "),a("ul",[a("li",[t._v("Cluster 和 Node")])]),t._v(" "),a("p",[t._v("ES可以以单点或者集群方式运行，以一个整体对外提供search服务的所有节点组成cluster，组成这个cluster的各个节点叫做node。单台服务器没有备用分片，因为主分片和备用分片不能再同一台机器上，切一个主分片对应一个副分片。索引的主分片被定义好后，不能被修改。")]),t._v(" "),a("ul",[a("li",[t._v("Index")])]),t._v(" "),a("p",[t._v("这是ES存储数据的地方，类似于关系数据库的database。")]),t._v(" "),a("ul",[a("li",[t._v("Shards")])]),t._v(" "),a("p",[t._v("索引分片，这是ES提供分布式搜索的基础，其含义为将一个完整的index分成若干部分存储在相同或不同的节点上，这些组成index的部分就叫做shard。")]),t._v(" "),a("ul",[a("li",[t._v("Replicas")])]),t._v(" "),a("p",[t._v("索引副本，ES可以设置多个索引的副本，副本的作用一是提高系统的容错性，当个某个节点某个分片损坏或丢失时可以从副本中恢复。二是提高ES的查询效率，ES会自动对搜索请求进行负载均衡。")]),t._v(" "),a("ul",[a("li",[t._v("Recovery")])]),t._v(" "),a("p",[t._v("代表数据恢复或叫数据重新分布，ES在有节点加入或退出时会根据机器的负载对索引分片进行重新分配，挂掉的节点重新启动时也会进行数据恢复。")]),t._v(" "),a("ul",[a("li",[t._v("Gateway")])]),t._v(" "),a("p",[t._v("ES索引快照的存储方式，ES默认是先把索引存放到内存中，当内存满了时再持久化到本地硬盘。gateway对索引快照进行存储，当这个ES集群关闭再重新启动时就会从gateway中读取索引备份数据。")]),t._v(" "),a("ul",[a("li",[t._v("Discovery.zen")])]),t._v(" "),a("p",[t._v("代表ES的自动发现节点机制，ES是一个基于p2p的系统，它先通过广播寻找存在的节点，再通过多播协议来进行节点之间的通信，同时也支持点对点的交互。")]),t._v(" "),a("ul",[a("li",[t._v("NTransport")])]),t._v(" "),a("p",[t._v("代表ES内部节点或集群与客户端的交互方式，默认内部是使用tcp协议进行交互，同时它支持http协议（json格式）。")]),t._v(" "),a("h3",{attrs:{id:"安装elasticsearch"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#安装elasticsearch"}},[t._v("#")]),t._v(" 安装elasticsearch")]),t._v(" "),a("p",[t._v("Elastic Search是一个开源的，分布式，实时搜索和分析引擎。ES是一个基于Lucene的分布式全文搜索服务器，和SQL Server的全文索引（Fulltext Index）有点类似，\n都是基于分词和分段的全文搜索引擎，具有分词，同义词，词干查询的功能，但是ES天生具有分布式和实时的属性")]),t._v(" "),a("p",[t._v("按照官方文档的内容进行操作："),a("a",{attrs:{href:"https://www.elastic.co/downloads/elasticsearch",target:"_blank",rel:"noopener noreferrer"}},[t._v("官网"),a("OutboundLink")],1)]),t._v(" "),a("p",[t._v("运行"),a("a",{attrs:{href:"http://localhost:9200",target:"_blank",rel:"noopener noreferrer"}},[t._v("http://localhost:9200"),a("OutboundLink")],1),t._v(" 查看是否启动成功")]),t._v(" "),a("blockquote",[a("p",[t._v("注意：安装目录不能包含中文和空格，如果含有空格需要用括号将其括起来。")])]),t._v(" "),a("p",[t._v("可选择根据需要选择相关配置：修改安装目下 ~/config/elasticsearch.yml文件， 相关配置参数：")]),t._v(" "),a("div",{staticClass:"language-yml extra-class"},[a("pre",{pre:!0,attrs:{class:"language-yml"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("##集群名称")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("cluster.name")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" elasticsearch\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("##节点名称")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("node.name")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"node1"')]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("##节点是否存储数据")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("node.data")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token boolean important"}},[t._v("true")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("##索引分片数")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("index.number_of_shards")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("##索引副本数")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("index.number_of_replicas")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("##数据目录存放位置")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("path.data")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" /data/elasticsearch/data\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("##日志数据存放位置")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("path.logs")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" /data/elasticsearch/log\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("##索引缓存")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("index.cache.field.max_size")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("500000")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("##索引缓存过期时间")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("index.cache.field.expire")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" 5m\n")])])]),a("p",[t._v("安装x-pack，地址与详细教程： "),a("a",{attrs:{href:"https://www.elastic.co/downloads/x-pack",target:"_blank",rel:"noopener noreferrer"}},[t._v("参考官网"),a("OutboundLink")],1)]),t._v(" "),a("blockquote",[a("p",[t._v("注意：执行设置自动密码命令"),a("code",[t._v("bin/x-pack/setup-passwords auto")]),t._v("，一定要先启动elasticsearch服务，然后用生成的密码去登陆。\n如果想自定义密码，用命令："),a("code",[t._v("bin/x-pack/setup-passwords interactive")]),t._v("，按照提示完成即可。")])]),t._v(" "),a("h3",{attrs:{id:"安装kibana插件"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#安装kibana插件"}},[t._v("#")]),t._v(" 安装Kibana插件")]),t._v(" "),a("p",[t._v("Kibana插件可做近实时系统数据分析，每个分片的刷新频率为1s一次")]),t._v(" "),a("p",[t._v("下载地址：https://www.elastic.co/downloads/kibana")]),t._v(" "),a("blockquote",[a("p",[t._v("注意，kibana 的版本必须与 ElasticSearch 的版本对应")])]),t._v(" "),a("p",[t._v("解压缩后，修改../config下的配置文件 kibana.yml")]),t._v(" "),a("div",{staticClass:"language-properties extra-class"},[a("pre",{pre:!0,attrs:{class:"language-properties"}},[a("code",[a("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("server.host")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token attr-value"}},[t._v("127.0.0.1")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("elasticsearch.url")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token attr-value"}},[t._v('"http://127.0.0.1:9200"')]),t._v("\n")])])]),a("p",[t._v("然后，浏览器直接访问 http://localhost:5601。\n"),a("img",{attrs:{src:"http://cdn.gqsu.top/es01-1.png",alt:""}})]),t._v(" "),a("p",[t._v("注意：未安装x-pack插件的kibana只具有基本功能，Monitoring、Graph等功能不能使用。")]),t._v(" "),a("p",[t._v("安装x-pack，地址与详细教程： https://www.elastic.co/guide/en/kibana/6.2/installing-xpack-kb.html")]),t._v(" "),a("p",[t._v("在线安装：进入kibana目录，运行"),a("code",[t._v("bin/kibana-plugin install x-pack")]),t._v("（linux用户注意不要使用root用户，可使用"),a("code",[t._v("sudo -u kibana bin/kibana-plugin install x-pack")]),t._v("）")]),t._v(" "),a("blockquote",[a("p",[t._v("若是在线安装出现问题，则需要手动安装，下载地址为："),a("code",[t._v("https://artifacts.elastic.co/downloads/packs/x-pack/x-pack-6.2.2.zip")]),t._v(",\n下载完成后，运行将后面的path路径指明为你的下载包存放路径即可："),a("code",[t._v("bin/kibana-plugin install file:///path/to/file/x-pack-6.2.3.zip")])])]),t._v(" "),a("p",[t._v("修改../config下的配置文件 kibana.yml")]),t._v(" "),a("div",{staticClass:"language-properties extra-class"},[a("pre",{pre:!0,attrs:{class:"language-properties"}},[a("code",[a("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("elasticsearch.username")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token attr-value"}},[t._v('"kibana"')]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("elasticsearch.password")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token attr-value"}},[t._v('"kibanapassword"')]),t._v("\n")])])]),a("blockquote",[a("p",[t._v("如报错， { statusCode: 400,\npayload:\n{ message:\n'closed: [index_closed_exception] closed, with { index_uuid=\"LXmoelQOSjig2ISDUUHmMA\" & index=\".kibana_1\" }',\nstatusCode: 400,\nerror: 'Bad Request' },\nheaders: {} },")]),t._v(" "),a("p",[t._v("尝试：http://localhost:9200/.kibana_1/_open（因为关闭索引后不能更新索引和查询索引内容，否则会抛出错误）")])]),t._v(" "),a("p",[t._v("这里关于 elastic、kibana和logstash用户的区别可参见："),a("a",{attrs:{href:"https://www.elastic.co/guide/en/kibana/6.2/settings-xpack-kb.htmlyml",target:"_blank",rel:"noopener noreferrer"}},[t._v("官方文档"),a("OutboundLink")],1)]),t._v(" "),a("h4",{attrs:{id:"配置主从集群-未验证-仅供参考"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#配置主从集群-未验证-仅供参考"}},[t._v("#")]),t._v(" 配置主从集群（未验证，仅供参考）：")]),t._v(" "),a("div",{staticClass:"language-yaml extra-class"},[a("pre",{pre:!0,attrs:{class:"language-yaml"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#主节点")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("bootstrap.memory_lock")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token boolean important"}},[t._v("false")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("bootstrap.system_call_filter")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token boolean important"}},[t._v("false")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("cluster.name")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" owen\n"),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("node.name")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" master\n"),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("node.master")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token boolean important"}},[t._v("true")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("network.host")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" 130.75.131.233\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#从节点1")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("bootstrap.memory_lock")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token boolean important"}},[t._v("false")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("bootstrap.system_call_filter")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token boolean important"}},[t._v("false")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("cluster.name")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" owen\n"),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("node.name")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" slave01\n"),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("network.host")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" 130.75.131.234\n"),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("discovery.zen.ping.unicast.hosts")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"130.75.131.233"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#从节点2")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("bootstrap.memory_lock")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token boolean important"}},[t._v("false")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("bootstrap.system_call_filter")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token boolean important"}},[t._v("false")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("cluster.name")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" owen\n"),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("node.name")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" slave02\n"),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("network.host")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" 130.75.131.235\n"),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("discovery.zen.ping.unicast.hosts")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"130.75.131.233"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n\n")])])]),a("h3",{attrs:{id:"安装ik分词"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#安装ik分词"}},[t._v("#")]),t._v(" 安装ik分词")]),t._v(" "),a("p",[t._v("下载地址为： https://github.com/medcl/elasticsearch-analysis-ik")]),t._v(" "),a("blockquote",[a("p",[t._v("注意，ik 分词的版本必须与 ElasticSearch 的版本对应。下载下来的为源代码，运行"),a("code",[t._v("mvn package")]),t._v("得到打包文件，并做一些其他操作。")])]),t._v(" "),a("p",[t._v("推荐直接使用编译好的文件，下载： https://github.com/medcl/elasticsearch-analysis-ik/releases\n解压缩后，更改最里层目录文件夹的名称为"),a("code",[t._v("ik")]),t._v("，并拷贝其至"),a("code",[t._v("elasticsearch-6.2.2/plugins")]),t._v("目录下")]),t._v(" "),a("p",[t._v("运行"),a("code",[t._v("elasticsearch-6.2.2/bin")]),t._v("下的 "),a("code",[t._v("elasticsearch.bat")]),t._v("，启动elasticsearch。")]),t._v(" "),a("p",[t._v("测试基本功能：")]),t._v(" "),a("div",{staticClass:"language-json extra-class"},[a("pre",{pre:!0,attrs:{class:"language-json"}},[a("code",[t._v("GET _analyze?pretty\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token property"}},[t._v('"analyzer"')]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"ik_smart"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("   "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//ik_smart和ik_max_word两个字段可选")]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token property"}},[t._v('"text"')]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"安徽省长江流域"')]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),a("p",[t._v("返回：")]),t._v(" "),a("div",{staticClass:"language-json extra-class"},[a("pre",{pre:!0,attrs:{class:"language-json"}},[a("code",[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token property"}},[t._v('"tokens"')]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n      "),a("span",{pre:!0,attrs:{class:"token property"}},[t._v('"token"')]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"安徽省"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n      "),a("span",{pre:!0,attrs:{class:"token property"}},[t._v('"start_offset"')]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n      "),a("span",{pre:!0,attrs:{class:"token property"}},[t._v('"end_offset"')]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n      "),a("span",{pre:!0,attrs:{class:"token property"}},[t._v('"type"')]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"CN_WORD"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n      "),a("span",{pre:!0,attrs:{class:"token property"}},[t._v('"position"')]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n      "),a("span",{pre:!0,attrs:{class:"token property"}},[t._v('"token"')]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"长江流域"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n      "),a("span",{pre:!0,attrs:{class:"token property"}},[t._v('"start_offset"')]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n      "),a("span",{pre:!0,attrs:{class:"token property"}},[t._v('"end_offset"')]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("7")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n      "),a("span",{pre:!0,attrs:{class:"token property"}},[t._v('"type"')]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"CN_WORD"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n      "),a("span",{pre:!0,attrs:{class:"token property"}},[t._v('"position"')]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),a("blockquote",[a("p",[t._v("默认使用的是标准分词器(standard)。扩展：使用自己的分词字典。")])]),t._v(" "),a("blockquote",[a("p",[t._v("这里需要特别指出的是，英文分词(english)会将的过去分词、现在分词、复数等形式的单词转换为最基本的形态。")])]),t._v(" "),a("p",[t._v("下载的analysis-ik都是别人定义好的一些已有字典。可新建new_word.dic，在里面定义自己的一些规范即可。")]),t._v(" "),a("p",[t._v("最后别忘了更改配置文件 IKAnalyzer.cfg.xml ，然后重启即可。")]),t._v(" "),a("div",{staticClass:"language-xml extra-class"},[a("pre",{pre:!0,attrs:{class:"language-xml"}},[a("code",[a("span",{pre:!0,attrs:{class:"token prolog"}},[t._v('<?xml version="1.0" encoding="UTF-8"?>')]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token doctype"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<!")]),a("span",{pre:!0,attrs:{class:"token doctype-tag"}},[t._v("DOCTYPE")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token name"}},[t._v("properties")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token name"}},[t._v("SYSTEM")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"http://java.sun.com/dtd/properties.dtd"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("properties")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("comment")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("IK Analyzer 扩展配置"),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("comment")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("\x3c!--用户可以在这里配置自己的扩展字典 --\x3e")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("entry")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("key")]),a("span",{pre:!0,attrs:{class:"token attr-value"}},[a("span",{pre:!0,attrs:{class:"token punctuation attr-equals"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v('"')]),t._v("ext_dict"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v('"')])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("custom/new_word.dic"),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("entry")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n     "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("\x3c!--用户可以在这里配置自己的扩展停止词字典--\x3e")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("entry")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("key")]),a("span",{pre:!0,attrs:{class:"token attr-value"}},[a("span",{pre:!0,attrs:{class:"token punctuation attr-equals"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v('"')]),t._v("ext_stopwords"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v('"')])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("entry")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("\x3c!--用户可以在这里配置远程扩展字典 --\x3e")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v('\x3c!-- <entry key="remote_ext_dict">words_location</entry> --\x3e')]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("\x3c!--用户可以在这里配置远程扩展停止词字典--\x3e")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v('\x3c!-- <entry key="remote_ext_stopwords">words_location</entry> --\x3e')]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("properties")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n")])])]),a("h3",{attrs:{id:"安装logstash"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#安装logstash"}},[t._v("#")]),t._v(" 安装Logstash")]),t._v(" "),a("blockquote",[a("p",[t._v("主要用于构建 ELK 服务，即安装 elasticsearch + Logstash + Kibana")])]),t._v(" "),a("p",[t._v("去官网下载：https://www.elastic.co/downloads/logstash")]),t._v(" "),a("p",[t._v("下载完成后，解压")]),t._v(" "),a("div",{staticClass:"language-shell extra-class"},[a("pre",{pre:!0,attrs:{class:"language-shell"}},[a("code",[a("span",{pre:!0,attrs:{class:"token builtin class-name"}},[t._v("cd")]),t._v(" logstash-6.2.2\nbin/logstash.bat -e "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'input { stdin { } } output { stdout {} }'")]),t._v("\n")])])]),a("p",[t._v("以上是正常的控制台写入输出模式。一定要注意"),a("code",[t._v("bin/logstash.bat")]),t._v("运行，不能切换到"),a("code",[t._v("bin")]),t._v("目录在运行。")]),t._v(" "),a("p",[t._v("按照官方建议，在当前目录下，新建 logstash.conf 文件加入配置：")]),t._v(" "),a("p",[t._v("这里以导入数据为例：")]),t._v(" "),a("div",{staticClass:"language-sh extra-class"},[a("pre",{pre:!0,attrs:{class:"language-sh"}},[a("code",[a("span",{pre:!0,attrs:{class:"token function"}},[t._v("file")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    path "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"F:/ElasticSearch/logstash-5.4.1/shakespeare.json/"')]),t._v("       "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("##数据源文件")]),t._v("\n    start_position "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"beginning"')]),t._v("\n    ignore_older "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v("\n    codec "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"json"')]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v('#    sincedb_path => "/dev/null"')]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token builtin class-name"}},[t._v("type")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"wjb_log"')]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\nfilter"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("bboy_id"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        mutate "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v(" add_tag "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"BBOY"')]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\noutput "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("bboy_id"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        elasticsearch "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n            hosts "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"localhost:9200"')]),t._v("\n            index "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"bboy-%{+YYYY.MM.dd}"')]),t._v("\n            document_type "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"bboy_log"')]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("else")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        elasticsearch "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n            hosts "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"localhost:9200"')]),t._v("\n            index "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"wjb-%{+YYYY.MM.dd}"')]),t._v("\n            document_type "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"wjb_log"')]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),a("p",[t._v("接着，只需运行配置文件即可。可通过 kibana 查看数据是否导入成功。")]),t._v(" "),a("div",{staticClass:"language-powershell extra-class"},[a("pre",{pre:!0,attrs:{class:"language-powershell"}},[a("code",[t._v("$ bin"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("logstash"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("bat "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("f logstash"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("conf\n")])])]),a("p",[t._v("完整的配置文件说明如下：")]),t._v(" "),a("div",{staticClass:"language-sh extra-class"},[a("pre",{pre:!0,attrs:{class:"language-sh"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#整个配置文件分为三部分：input,filter,output")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#参考这里的介绍 https://www.elastic.co/guide/en/logstash/current/configuration-file-structure.html")]),t._v("\ninput "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#file可以多次使用，也可以只写一个file而设置它的path属性配置多个文件实现多文件监控")]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("file")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v('#type是给结果增加了一个属性叫type值为"<xxx>"的条目。这里的type，对应了ES中index中的type，即如果输入ES时，没有指定type，那么这里的type将作为ES中index的type。')]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token builtin class-name"}},[t._v("type")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"apache-access"')]),t._v(" \n    path "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"/apphome/ptc/Windchill_10.0/Apache/logs/access_log*"')]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#start_position可以设置为beginning或者end，beginning表示从头开始读取文件，end表示读取最新的，这个也要和ignore_older一起使用。")]),t._v("\n    start_position "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" beginning\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#sincedb_path表示文件读取进度的记录，每行表示一个文件，每行有两个数字，第一个表示文件的inode，第二个表示文件读取到的位置（byteoffset）。默认为$HOME/.sincedb*")]),t._v("\n    sincedb_path "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"/opt/logstash-2.3.1/sincedb_path/access_progress"')]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#ignore_older表示了针对多久的文件进行监控，默认一天，单位为秒，可以自己定制，比如默认只读取一天内被修改的文件。")]),t._v("\n    ignore_older "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("604800")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#add_field增加属性。这里使用了${HOSTNAME}，即本机的环境变量，如果要使用本机的环境变量，那么需要在启动命令上加--alow-env。")]),t._v("\n    add_field "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"log_hostname"')]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"'),a("span",{pre:!0,attrs:{class:"token variable"}},[t._v("${"),a("span",{pre:!0,attrs:{class:"token environment constant"}},[t._v("HOSTNAME")]),t._v("}")]),t._v('"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v('#这个值默认是\\n 换行符，如果设置为空""，那么后果是每个字符代表一个event')]),t._v("\n    delimiter "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('""')]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#这个表示关闭超过（默认）3600秒后追踪文件。这个对于multiline来说特别有用。... 这个参数和logstash对文件的读取方式有关，两种方式read tail，如果是read")]),t._v("\n    close_older "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("3600")]),t._v("\n    coodec "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" multiline "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n      pattern "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"^\\s"')]),t._v("\n      "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#这个negate是否定的意思，意思跟pattern相反，也就是不满足patter的意思。")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v('#      negate => ""')]),t._v("\n      "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#what有两个值可选 previous和next，举例说明，java的异常从第二行以空格开始，这里就可以pattern匹配空格开始，what设置为previous意思是空格开头这行跟上一行属于同一event。另一个例子，有时候一条命令太长，当以\\结尾时表示这行属于跟下一行属于同一event，这时需要使用negate=>true，what=>'next'。")]),t._v("\n      what "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"previous"')]),t._v("\n      auto_flush_interval "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("60")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("file")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v(" \n    "),a("span",{pre:!0,attrs:{class:"token builtin class-name"}},[t._v("type")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"methodserver-log"')]),t._v(" \n    path "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"/apphome/ptc/Windchill_10.0/Windchill/logs/MethodServer-1604221021-32380.log"')]),t._v(" \n    start_position "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" beginning \n    sincedb_path "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"/opt/logstash-2.3.1/sincedb_path/methodserver_process"')]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#    ignore_older => 604800")]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\nfilter"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#执行ruby程序，下面例子是将日期转化为字符串赋予daytag")]),t._v("\n  ruby "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    code "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("\"event['daytag'] = event.timestamp.time.localtime.strftime('%Y-%m-%d')\"")]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v('# if [path] =~ "access" {} else if [path] =~ "methodserver" {} else if [path] =~ "servermanager" {} else {} 注意语句结构')]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("path"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("~ "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"MethodServer"')]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#z这里的=~是匹配正则表达式")]),t._v("\n    grok "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n      patterns_dir "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"/opt/logstash-2.3.1/patterns"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#自定义正则匹配")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#      Tue 4/12/16 14:24:17: TP-Processor2: hirecode----\x3e77LS")]),t._v("\n      match "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"message"')]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"%{DAY:log_weekday} %{DATE_US:log_date} %{TIME:log_time}: %{GREEDYDATA:log_data}"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#mutage是做转换用的")]),t._v("\n    mutate "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v(" \n      replace "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"type"')]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"apache"')]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#替换属性值")]),t._v("\n      convert "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#类型转换")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"bytes"')]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"integer"')]),t._v(" "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#例如还有float")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"duration"')]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"integer"')]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"state"')]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"integer"')]),t._v("\n      "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#date主要是用来处理文件内容中的日期的。内容中读取的是字符串，通过date将它转换为@timestamp。参考https://www.elastic.co/guide/en/logstash/current/plugins-filters-date.html#plugins-filters-date-match")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#    date {")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v('#      match => [ "logTime" , "dd/MMM/yyyy:HH:mm:ss Z" ]')]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#    }")]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("else "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("type"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'tbg_qas'")]),t._v(","),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'mbg_pre'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# if ... else if ... else if ... else结构")]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("else "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    drop"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 将event丢弃")]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\noutput "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  stdout"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token assign-left variable"}},[t._v("codec")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("rubydebug"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 直接输出，调试用起来方便")]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 输出到redis")]),t._v("\n  redis "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("host")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'10.120.20.208'")]),t._v("\n    data_type "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'list'")]),t._v("\n    key "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'10.99.201.34:access_log_2016-04'")]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 输出到ES")]),t._v("\n  elasticsearch "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    hosts "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"192.168.0.15:9200"')]),t._v("\n    index "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"%{sysid}_%{type}"')]),t._v("\n    document_type "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"%{daytag}"')]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),a("p",[t._v("使用参考1：http://blog.51cto.com/tchuairen/1840596")]),t._v(" "),a("p",[t._v("使用参考2：https://blog.csdn.net/iguyue/article/details/77006201")])])}),[],!1,null,null,null);s.default=e.exports}}]);